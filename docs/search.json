[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Giorgio’s pages",
    "section": "",
    "text": "I got a Ph.D in materials science and I’m a researcher with a variety of interests. I currently works as a researcher at the Italian National Council of Research (CNR) on topics related to the characterization and development of new materials.My interests also focus on lighting and rendering and creating scientific illustration. Here you will find my spaghetti code tutorials, blend files and other doodles\n\n\nhttps://github.com/giorgioluciano\n\n\n\nhttps://giorgioluciano.github.io/CrystalNodes/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a Chemist that works as a researcher at the National Research Council of Italy. I work on characterization of materials and data analysis. I code in Python and R and I like Computer Graphics and Illustration\nAbout this blog\nin this blog I share the code that I write in my everyday work and also fun stuff that I find on other blogs and site about data analytics"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "docs/posts/R Packages/index.html",
    "href": "docs/posts/R Packages/index.html",
    "title": "Fun with Data",
    "section": "",
    "text": "Don’t trust boxplot\n\ncategories: [r,ggplot,recipes]\n\n\n# Author: Giorgio Luciano\n# Title: boxplot fun\n# Date: 16/2/2023\n# Status: checked working\n##---------------------------------------------------------------\n\n# Step 1: Load libraries\n\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(data.table)\nlibrary(RColorBrewer)\nlibrary(ggpubr)\nlibrary(rstatix, warn.conflicts = FALSE)\nlibrary(ggrepel)\nlibrary(ggpubr)\nlibrary(patchwork)\n\n# Step 2: Write a function for generating data with custom number of rows, means and sds\n\nsimpleDataset <- function(number_of_rows, means, sds)\n{\nl <- length( means )\nres <- lapply(seq(1:l),function(x) \n       eval(parse(text=paste(\"rnorm(\",number_of_rows,\",\",means[x],\",\",sds[x],\")\",sep = \"\")))) \ndat <- data.frame((sapply(res,c)))\nid <- rownames(dat)\ndat <-  cbind(id = id,dat)\ndt <- data.table(dat)\nreturn(dt)\n}\n\ndat1 <- simpleDataset(number_of_rows=100,\n                      means = runif(10,100,150),\n                      sds = runif(10,10,40))\n\noutliers <- simpleDataset(number_of_rows=5,\n                      means = runif(10,60,80),\n                      sds = runif(10,10,10))                  \n\ndato     <-rbind(dat1,outliers) \n\ndt.melt <- melt(dat1, id.vars=\"id\")\ncolnames(dt.melt) <- c(\"id\",\"category\",\"var1\")\ndt.melt$ncat <- as.numeric(dt.melt$category)\n\n#Step 3:    Jiitter plots + boxplot + brackets \n\n#setting up dimensions\noptions(repr.plot.width=8.9, repr.plot.height=8.9,units=\"cm\")\n\n#adding jiitter plot\n\np <-  ggplot(dt.melt,aes(x=factor(ncat),y=var1))        +\n      geom_jitter(position = position_jitter(0.15),alpha=0.5,size = 3) +\n      geom_boxplot(alpha = 0,lwd=0.2) \n##---------------------------------------------------------------\n\nSo for now everything on track. We created a dataset using a custom function. 10 variables with 100 points each and them we plot them using scatter plots. Before plotting a few more data we need to answer the question\n*How are boxplot constructed?* (*warning*: shameless self-promotion ahead) First of all you can check on my book/ebook [https://amzn.com/B08W8W5WSF](https://amzn.com/B08W8W5WSF)\nNow it starts the fun part we will recreate a plot on the anatomy of a boxplot (see [here](https://www.sharpsightlabs.com/blog/ggplot-boxplot/)) using ggplot.\n\n# we create a dataset and add a few outliers\n# \ny   <- c(60,63,105,155,rnorm(100,80,25))\nbox <-  ggplot()                                               +\n        theme_void()                                           +\n        geom_boxplot(aes(x=0,y=y),width=1,notch = FALSE,lwd=1) +  \n        theme(legend.position = \"none\")                        +\n        lims( x = c(-2,2) )\n      \n#how can we  get out data? using the function ggplot_build()\n#need to change it to a data.frame and rename cols\n\nbox_data <- (ggplot_build(box)$data)[[1]]\nbox_data\n\n      ymin    lower   middle    upper     ymax outliers notchupper notchlower x\n1 16.81564 58.19611 75.04227 96.32843 130.8743      155   80.95017   69.13436 0\n  flipped_aes PANEL group ymin_final ymax_final xmin xmax xid newx new_width\n1       FALSE     1    -1   16.81564        155 -0.5  0.5   1    0         1\n  weight colour  fill size alpha shape linetype\n1      1 grey20 white    1    NA    19    solid\n\nbdata <- data.frame(t(box_data[c(1,2,3,4,5,14)]))\ncolnames(bdata) <- c(\"y\")\n#we need to transpose the data and convert them to a data frame\n#now we extract the ourliers \noutl  <- data.frame(box_data$outliers)\ncolnames(outl)  <- c(\"outl\")\n\n#now that I got the data I plot everything with labels\np2 <- box + geom_text (data=bdata,aes(\n                      x=1.5,\n                      y=y,\n                      label = c(\"min\",\"Lower Q\",\"Median\",\"Upper Q\",\"max\",\"outliers\")), size = 2)+\n                      geom_segment(data = bdata, aes(x = 0.8, y = y, xend = 0.7, yend = y),lwd=1)  \n                        \n#since we have created the dataset WITH outliers we include labels also for them\n#if your dataset has no outliers you need to commet this part out\n    \np2 + geom_text_repel(data=outl,aes(x=0.1, y=outl,label=format(round(outl, 2), nsmall = 2)),size= 2) \n\n\n\n\n*notes on the code:* we create our variable `y` with `rnorm` and we add a few outliers by hand then we create the boxplot with an empty theme using `theme_void()`. The funny part start when we ask ggplot to show how the plot was built with the `ggplot_build`. We then need to rotate (`t`) the selected columns `c(1,2,3,4,5,14)` ,convert the results into a `data.frame`, rename the columns (`colnames`) and then use them (our `y`) to add labvels to our plot using `geom_text`\nAnother representation of boxplot can also include *notch*. the default is not to visualuize them but just adding `notch=true` to the previous plot we will do the trick\n\nboxnotch <-  ggplot()                                               +\n             theme_void()                                           +\n             geom_boxplot(aes(x=0,y=y),width=1,notch = TRUE,lwd=1)  +  \n             theme(legend.position = \"none\")                        +\n             lims(x=c(-2,4))\nnotchdata <- data.frame(t(box_data[c(7,8)]))\ncolnames(notchdata) <- c(\"y_notch\")\n#we need to transpose the data and convert them to a data frame\n\n#now that I got the data I plot everything with labels\np3 <- boxnotch +  geom_segment(data=notchdata, aes(x = 0.8, \n                                                   y = mean(y_notch),\n                                                   xend = 0.6, yend = y_notch\n                                                   ),lwd=1)\np4 <- p3 + annotate(geom=\"text\", x=2.5, y= mean(notchdata$y_notch),\n                    label=\"notch (95% confidence\\ninterval of median)\",size=4)\np4\n\n\n\n\nok but what if multiple dataset have same statistics? Like in the case of the datasaurus package(Matejka and Fitzmaurice 2017)\n\nlibrary(datasauRus)\n\nWarning: package 'datasauRus' was built under R version 4.2.2\n\nsummary(box_plots)\n\n      left              lines               normal          right       \n Min.   :-9.76964   Min.   :-9.769575   Min.   :-9.76   Min.   :-9.760  \n 1st Qu.:-2.68999   1st Qu.:-2.689993   1st Qu.:-2.68   1st Qu.:-2.680  \n Median :-0.00999   Median :-0.007132   Median : 0.00   Median : 0.000  \n Mean   :-1.17780   Mean   :-0.831733   Mean   : 0.00   Mean   : 1.174  \n 3rd Qu.: 2.67007   3rd Qu.: 2.670236   3rd Qu.: 2.68   3rd Qu.: 2.680  \n Max.   : 9.75025   Max.   : 9.756001   Max.   : 9.76   Max.   : 9.760  \n     split          \n Min.   :-9.769886  \n 1st Qu.:-2.689989  \n Median :-0.003099  \n Mean   :-0.003060  \n 3rd Qu.: 2.680000  \n Max.   : 9.760000  \n\np1 <-ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_jitter(alpha=0.05)                                 +\ntheme_void()  \n\np2 <- ggplot(stack(box_plots), aes(x = ind, y = values))+\ngeom_boxplot(lwd=0.05) +\ntheme_void()  \np1+p2\n\n\n\n\nWe can see that plotting the raw points even for hundreds of points works and represent well our data. In this case adding notch does not solve the problem. Other kind of plot get not fooled by our data as it can be seen in the following figure:\n\npnotch <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_boxplot(notch=TRUE)  +  ggtitle(\"(notch=TRUE)\")\n  \npjitter <-ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_jitter(alpha=0.05)  +  ggtitle(\"geom_jitter\") \n\npviolin <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_violin(lwd=1)  +  ggtitle(\"geom_violin\") \n\npnotch \n\n\n\npjitter \n\n\n\npviolin\n\n\n\n\nOther packages\n1. beeswarm plot ggbeeswarm [https://github.com/eclarke/ggbeeswarm] (and here the things start getting artistic too!) (note: not all representation for this dataset work due to the number of points)\n\nlibrary(ggbeeswarm)\n\nWarning: package 'ggbeeswarm' was built under R version 4.2.2\n\np_qrandom0 <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_quasirandom(alpha=0.05)  +  ggtitle(\"quasi_random\") \n\n#p_qrandom0\n\np_qrandom1 <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_quasirandom(alpha=0.05,method = \"tukey\")  +  ggtitle(\"Tukey\") \n\n#p_qrandom1\n\np_qrandom2 <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_quasirandom(alpha=0.05,method = \"tukeyDense\")   +  ggtitle(\"Tukey + density\") \n\n#p_qrandom2\n\np_qrandom3 <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_quasirandom(alpha=0.05,method = \"tukeyDense\")   +  ggtitle(\"Banded frowns\") \n\n#p_qrandom3\n\np_qrandom4 <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_quasirandom(alpha=0.05,method = \"frowney\")   +  ggtitle(\"Banded smiles\") \n\n#p_qrandom4\n\n#too many points\n#p_beeswarm <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\n#geom_beeswarm(alpha=0.05) +  ggtitle(\"beeswarm\") \n\np_qrandom0\n\n\n\np_qrandom1\n\n\n\np_qrandom2\n\n\n\n\nyou can halso mix plot a useful package for that is gghalves\n\nlibrary(gghalves)\n\nWarning: package 'gghalves' was built under R version 4.2.2\n\npoint_half <- ggplot(stack(box_plots), aes(x = ind, y = values)) +\ngeom_half_point(alpha=0.05) \n\ngeom_half_violin() \n\ngeom_half_violin: side = l, nudge = 0, draw_quantiles = NULL, na.rm = FALSE\nstat_half_ydensity: trim = TRUE, scale = area, na.rm = FALSE\nposition_dodge \n\npoint_half\n\n\n\n\nfinally a very useful package, also my favorite one for EDA ggstatplotthat you can find here that calculate also a lot of useful stats and combine different kind of plot in one plot\n\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\n\n\nAttaching package: 'ggstatsplot'\n\n\nThe following object is masked from 'package:data.table':\n\n    :=\n\nstackbox <- stack(box_plots)\n\npstack  <- ggbetweenstats(\n  data = stackbox,\n  x = ind,\n  y = values,\n)\npstack \n\n\n\n\n\n\n\n\nReferences\n\nMatejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs.” Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, May. https://doi.org/10.1145/3025453.3025912."
  },
  {
    "objectID": "posts/Tip01/index.html",
    "href": "posts/Tip01/index.html",
    "title": "Tip 1: ggplot loops",
    "section": "",
    "text": "Summary\n\nCreate an empty list\nPopulate your list with objects (ggplots)\nCreate iteratively names for the objects\nRename the objects inside the list using the name list generated previously\nShow all plots using wrap_plots\n\nInstead of using boring plots we will use our private art collections and items.\nOne great package to create your art in R is aRtsy Let’s fire it up\n\nrequire(aRtsy)\n\nLoading required package: aRtsy\n\n\nWarning: package 'aRtsy' was built under R version 4.2.2\n\nrequire(patchwork)\n\nLoading required package: patchwork\n\n\n\n#before starting for having a look at the palette \n?colorPalette\n\nstarting httpd help server ... done\n\n\nCreate a Mondrian and save it\n\nset.seed(23)\nComposition_10 <- canvas_squares(colors = colorPalette(\"boogy2\"))\nsaveCanvas(Composition_10 , filename = \"Mondrian.png\")\nComposition_10 \n\n\n\n\nand another one\n\nset.seed(1)\naspect_ratio <- 1\nheight <- 2\nComposition_1 = canvas_segments(colors = colorPalette(\"blackwhite\"))\nComposition_1 \n\n\n\n\nor if you want to create a lots of them, create names automatically and then take a look at just one of your artistic composition in your collection use the following code:\n\nn_items <- 3\ncollection <- list()\nname_of_Composition  <- list()\nfor (i in 1:n_items) {\n  seed <-  (sample(1:100000,1)) + 1\n  name_of_Composition[[i]] <- paste0(\"Composition_\", i)\n  collection[[i]] <- canvas_squares(colors = colorPalette(\"boogy2\"))\n  \n}\nnames(collection) <- name_of_Composition\n\ncollection\n\n$Composition_1\n\n\n\n\n\n\n$Composition_2\n\n\n\n\n\n\n$Composition_3\n\n\n\n\n\n\n#as you can notice the setting for figure output in this chunk was changed in order to showplots with a rato of 3:1\nwrap_plots(collection)\n\n\n\n\n(Pedersen 2022) [Wickham (2016)](Derks 2022)\n\n\n\n\nReferences\n\nDerks, Koen. 2022. “aRtsy: Generative Art with ’Ggplot2’.” https://CRAN.R-project.org/package=aRtsy.\n\n\nPedersen, Thomas Lin. 2022. “Patchwork: The Composer of Plots.” https://CRAN.R-project.org/package=patchwork.\n\n\nWickham, Hadley. 2016. “Ggplot2: Elegant Graphics for Data Analysis.” https://ggplot2.tidyverse.org."
  },
  {
    "objectID": "posts/Tip02/index.html",
    "href": "posts/Tip02/index.html",
    "title": "Tip 2: Cleaning column names of an imported csv",
    "section": "",
    "text": "Summary\n\nImport data from a csv file\nUse the function clean_names from (Firke 2023)j R function\nWrite a function in base using gsub and regex to tackle specific issues\nYou’re done\n\nFirst of all we import the csv using the library (Müller 2020)here\n\nlibrary(here)\n\nWarning: package 'here' was built under R version 4.2.2\n\n\nhere() starts at D:/giorgioluciano.github.io\n\nfile_in <- \"FakeData.csv\"\npath_in <- \"posts/Tip02/\"\ndata <- read.csv(here(path_in,file_in), head=T, check.names=F, encoding=\"latin1\")\n\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.2.2\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ndata_fixed <- clean_names(data)\n\nAnd now the function written by William Doane\n\nclinical_names <- function(.data, unique = FALSE) {\n  n <- if (is.data.frame(.data)) colnames(.data) else .data\n  n <- gsub(\"cvrisk\", \"CVrisk\", n , ignore.case=T)\n  n <- gsub(\"hbo\", \"HBO\", n , ignore.case=T)\n  n <- gsub(\"ft4\", \"fT4\", n , ignore.case=T)\n  n <- gsub(\"f_t4\", \"fT4\", n , ignore.case=T)\n  n <- gsub(\"ft3\", \"fT3\", n , ignore.case=T)\n  n <- gsub(\"f_t3\", \"fT3\", n , ignore.case=T)\n  n <- gsub(\"ldl\", \"LDL\", n , ignore.case=T)\n  n <- gsub(\"hdl\", \"HDL\", n , ignore.case=T)\n  n <- gsub(\"hba1c\", \"HbA1C\", n, ignore.case=T)\n  n <- gsub(\"hbac1\", \"HbA1C\", n, ignore.case=T)\n  n <- gsub(\"hb_ac1\", \"HbA1C\",n,ignore.case=T)\n  n <- gsub(\"\\\\igf\\\\b\", \"IGF\", n , ignore.case=T)\n  n <- gsub(\"tsh\", \"TSH\", n , ignore.case=T)\n  n <- gsub(\"acth\", \"ACTH\", n, ignore.case=T)\n  n <- gsub(\"\\\\Na\\\\b\", \"Sodio\", n)\n  n <- gsub(\"\\\\K\\\\b\",  \"Potassio\", n)\n  n <- gsub(\"\\\\P\\\\b\",  \"Fosforo\", n)\n  n <- gsub(\"\\\\pas\\\\b\", \"PAS\", n, ignore.case=T)\n  n <- gsub(\"\\\\pad\\\\b\", \"PAD\", n, ignore.case=T)\n  n <- gsub(\"\\\\pth\\\\b\", \"PTH\", n, ignore.case=T)\n  n <- gsub(\"\\\\clu\\\\b\", \"CLU\", n, ignore.case=T)\n  n <- gsub(\"\\\\tg\\\\b\", \"TG\", n, ignore.case=T)\n  n <- gsub(\"\\\\glic\\\\b\", \"glicemia\", n, ignore.case=T)\n  if (unique) n <- make.unique(n, sep = \"_\")\n  if (is.data.frame(.data)) {\n    colnames(.data) <- n\n    .data\n  } else {\n    n\n  }\n}\n\n\ndata_clean <- clinical_names(data_fixed)\n\ncomparison <- cbind(data.frame((colnames(data))),\n                        data.frame((colnames(data_fixed))),\n                        data.frame((colnames(data_clean))))\n\ncolnames(comparison) <- c(\"original\",\"fixed\",\"clean\") \n\ncomparison\n\n           original             fixed             clean\n1          paziente          paziente          paziente\n2               età               eta               eta\n3               SEX               sex               sex\n4          diagnosi          diagnosi          diagnosi\n5           terapia           terapia           terapia\n6             tempo             tempo             tempo\n7            Cvrisk            cvrisk            CVrisk\n8              peso              peso              peso\n9        delta Peso        delta_peso        delta_peso\n10              BMI               bmi               bmi\n11         deltaBMI         delta_bmi         delta_bmi\n12              PAS               pas               PAS\n13         deltaPas         delta_pas         delta_PAS\n14              pad               pad               PAD\n15         deltaPad         delta_pad         delta_PAD\n16              HBO               hbo               HBO\n17           neutro            neutro            neutro\n18            linfo             linfo             linfo\n19             glic              glic          glicemia\n20    deltaglicemia     deltaglicemia     deltaglicemia\n21            HBAC1             hbac1             HbA1C\n22       deltaHbAc1      delta_hb_ac1       delta_HbA1C\n23            sodio             sodio             sodio\n24         potassio          potassio          potassio\n25           calcio            calcio            calcio\n26          fosforo           fosforo           fosforo\n27      colesterolo       colesterolo       colesterolo\n28 deltaColesterolo delta_colesterolo delta_colesterolo\n29              HDL               hdl               HDL\n30         deltaHDL         delta_hdl         delta_HDL\n31              ldl               ldl               LDL\n32         deltaLDL         delta_ldl         delta_LDL\n33               TG                tg                tg\n34          deltaTG          delta_tg          delta_tg\n35             ACTH              acth              ACTH\n36        cortisolo         cortisolo         cortisolo\n37              CLU               clu               CLU\n38              IGF               igf               IGF\n39              TSH               tsh               TSH\n40              fT4              f_t4               fT4\n41              PTH               pth               PTH\n42       Vitamina D        vitamina_d        vitamina_d\n43          dose_CA           dose_ca           dose_ca\n44          dose_HC           dose_hc           dose_hc\n45          dose_PL           dose_pl           dose_pl\n46 dose equivalente  dose_equivalente  dose_equivalente\n\n\n\n\n\n\nReferences\n\nFirke, Sam. 2023. “Janitor: Simple Tools for Examining and Cleaning Dirty Data.” https://CRAN.R-project.org/package=janitor.\n\n\nMüller, Kirill. 2020. “Here: A Simpler Way to Find Your Files.” https://CRAN.R-project.org/package=here."
  },
  {
    "objectID": "posts/Tip03/index.html",
    "href": "posts/Tip03/index.html",
    "title": "Tip 3: Functions for simulating data",
    "section": "",
    "text": "Summary\n\nExample of creating variables using runif and rnorm\nWriting a function that wraps all\n\nFirst of all we use the runif and rnorm to have a look how they work.\n\nlibrary(data.table)\nx_min   <- 0\nx_max   <- 10   \nx_step  <- 0.01\n\ny_mean  <- 0.5\ny_sd    <- 0.25\ny_min   <- -1\ny_max   <- 1   \n\nx       <- seq(x_min,x_max,x_step)\nvar_random  <- runif(x,y_min,y_max)\nvar_norm    <- rnorm(x,y_mean,y_sd) \n\ndf  <- data.frame (x,var_random,var_norm)\ndt  <- data.table(df)\n\n\nsimpleDataset <- function(number_of_rows,means,sds)\n{\nl <- length(means)\nres <- lapply(seq(1:l),function(x) \n       eval(\n       parse(\n       text=paste(\"rnorm(\",number_of_rows,\",\",means[x],\",\",sds[x],\")\",sep=\"\"))\n       )\n       ) \ndat <- data.frame((sapply(res,c)))\nid <- rownames(dat)\ndat <-  cbind(id=id,dat)\ndt <- data.table(dat)\nreturn(dt)\n}\n\nExample: We simulate the values of the LDL cholesterol of 2 patients in 3 different times. The first one patient (X1) has an average value of 200 of LDL with a standard variation of 2 while the second (X2) has an average of 150 with a standard deviation of 10. Note: All values are expressed in mg/dL\n\ndataset1 <- simpleDataset(3,c(200,180),c(2,10))\ndataset1\n\n   id       X1       X2\n1:  1 200.6442 196.5358\n2:  2 200.6801 166.5065\n3:  3 200.4200 196.2089\n\n\nExample: this time we combine runif and simpleDataset. We simulate the values of the LDL cholesterol of 5 patients in 7 different times. The values for each patient are between a min = 100 and a max = 150 with a standard deviation between a min sd = 10 and max sd = 40. We also simulate two time that presents outliers values between a min = 180 and max = 200 and an min sd = 10 and max sd = 40 . We merge the values for each patient (7 times + 2 outliers times) and finally we use the function melt to reshape the dataset.\n\ndat1 <- simpleDataset(number_of_rows=7,\n                      means=runif(5,100,150),\n                      sds=runif(5,10,40))\noutliers <- simpleDataset(number_of_rows=2,\n                      means=runif(5,180,200),\n                      sds=runif(5,10,40))                 \n\ndat1\n\n   id        X1       X2        X3        X4       X5\n1:  1  97.92524 105.5036 110.66623  34.45252 108.1226\n2:  2 169.96962 136.5666  97.62086 -11.68481 135.7269\n3:  3  77.46899 135.7573  93.37948 133.03592 129.4088\n4:  4 197.75026 168.3904 132.91647 154.98579 164.1461\n5:  5 121.99923 140.2879 127.80267 165.29857 158.9153\n6:  6 176.63684 127.6318 107.84311 138.62779 157.1849\n7:  7 117.90619 176.1431  99.01017 166.91662 219.9138\n\noutliers\n\n   id       X1       X2       X3       X4       X5\n1:  1 202.0947 191.3382 138.8483 194.0729 207.0543\n2:  2 194.0590 196.3606 209.5827 248.9402 175.0254\n\ndato     <-rbind(dat1,outliers) \ndt.melt <- melt(dat1, id.vars=\"id\")\ncolnames(dt.melt) <- c(\"id\",\"category\",\"var1\")\ndt.melt$ncat <- as.numeric(dt.melt$category)\n\ndt.melt\n\n    id category      var1 ncat\n 1:  1       X1  97.92524    1\n 2:  2       X1 169.96962    1\n 3:  3       X1  77.46899    1\n 4:  4       X1 197.75026    1\n 5:  5       X1 121.99923    1\n 6:  6       X1 176.63684    1\n 7:  7       X1 117.90619    1\n 8:  1       X2 105.50360    2\n 9:  2       X2 136.56661    2\n10:  3       X2 135.75728    2\n11:  4       X2 168.39042    2\n12:  5       X2 140.28791    2\n13:  6       X2 127.63183    2\n14:  7       X2 176.14312    2\n15:  1       X3 110.66623    3\n16:  2       X3  97.62086    3\n17:  3       X3  93.37948    3\n18:  4       X3 132.91647    3\n19:  5       X3 127.80267    3\n20:  6       X3 107.84311    3\n21:  7       X3  99.01017    3\n22:  1       X4  34.45252    4\n23:  2       X4 -11.68481    4\n24:  3       X4 133.03592    4\n25:  4       X4 154.98579    4\n26:  5       X4 165.29857    4\n27:  6       X4 138.62779    4\n28:  7       X4 166.91662    4\n29:  1       X5 108.12259    5\n30:  2       X5 135.72688    5\n31:  3       X5 129.40880    5\n32:  4       X5 164.14611    5\n33:  5       X5 158.91531    5\n34:  6       X5 157.18490    5\n35:  7       X5 219.91383    5\n    id category      var1 ncat\n\nstr(dt.melt)\n\nClasses 'data.table' and 'data.frame':  35 obs. of  4 variables:\n $ id      : chr  \"1\" \"2\" \"3\" \"4\" ...\n $ category: Factor w/ 5 levels \"X1\",\"X2\",\"X3\",..: 1 1 1 1 1 1 1 2 2 2 ...\n $ var1    : num  97.9 170 77.5 197.8 122 ...\n $ ncat    : num  1 1 1 1 1 1 1 2 2 2 ...\n - attr(*, \".internal.selfref\")=<externalptr>"
  },
  {
    "objectID": "posts/Tip04/index.html",
    "href": "posts/Tip04/index.html",
    "title": "Tip 4: boxplots and scatterplots: simple recipes",
    "section": "",
    "text": "Summary\n\nSimulate data, check and assign data types\nCreate a scatterplot with ggplot\nCreate violin plot with ggstatsplot\n\nExample 1 we want to visualize the difference between two groups of patients that follow two different diets. Group A has an average of total cholesterol of 180 with a standard deviation of 20 while Group B and average of 200 with a standard deviation of 40\n\nlibrary(MASS)\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.2\n\nlibrary(data.table)\n\n\nnpatientsA <- 500\nnpatientsB <- 520\ncholA <- mvrnorm(n=npatientsA, mu=180, Sigma=20, empirical=T)\ncholB <- mvrnorm(n=npatientsB, mu=200, Sigma=40, empirical=T)\n\ndataA <- cbind(cholA,rep(\"A\",npatientsA))  \ndataB <- cbind(cholB,rep(\"B\",npatientsB))  \n\ndata <- data.frame(rbind(dataA,dataB))\ncolnames(data) <- c(\"Cholesterol\",\"group\")\ndata$Cholesterol <- as.numeric(data$Cholesterol)\n\np1 <-ggplot(data, aes(x = group, y = Cholesterol)) + geom_jitter(alpha=0.05) \n\np1\n\n\n\n\na few observation on the code. First of all, we need to input the data in a data.frame otherwise ggplot will give us an error. the second observation is that since we put chr labels on our groups we needed to define Cholesterol as.numeric in order to avoid strange results. Try to comment the line data$Cholesterol <- as.numeric(data$Cholesterol) and you can see by yourself what will happen. (hint: a “labelstorm!”)\nThis very simple plot is one of my favorite. It let you see the raw data and immediately understand the distribution of your data and also avoid the pitfall of boxplot (see (Matejka and Fitzmaurice 2017))\nIf you need inferential statistics on your data another resource is (Patil 2021). See the following example with our data. NOTE that we nee to transform the group label as.factor\n\nlibrary(ggstatsplot)\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\n\n\nAttaching package: 'ggstatsplot'\n\n\nThe following object is masked from 'package:data.table':\n\n    :=\n\ndata$group <- as.factor(data$group)\n\npstack  <- ggbetweenstats(data,group,Cholesterol)\n                          \npstack    \n\n\n\n\n\n\n\n\nReferences\n\nMatejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs.” Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, May. https://doi.org/10.1145/3025453.3025912.\n\n\nPatil, Indrajeet. 2021. “Visualizations with Statistical Details: The ’Ggstatsplot’ Approach” 6: 3167. https://doi.org/10.21105/joss.03167."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html",
    "href": "posts/Packages Review 2022/index.html",
    "title": "R Packages 2022 list",
    "section": "",
    "text": "Summary"
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#plot",
    "href": "posts/Packages Review 2022/index.html#plot",
    "title": "R Packages 2022 list",
    "section": "Plot",
    "text": "Plot\n\nggvoronoi: Voronoi Diagrams and Heatmaps with ‘ggplot2’\ntags: #ggplot #tidyverse #voronoi\n[cran package link] https://CRAN.R-project.org/package=ggvoronoi\n\ndescription from the author/vignette\n\n\nEasy creation and manipulation of Voronoi diagrams using ‘deldir’ with visualization in ‘ggplot2’. Convenient functions are provided to create nearest neighbor diagrams and heatmaps. Diagrams are computed with ‘deldir’ and processed to work with the ‘sp’ framework. Results are provided in a convenient spatial data structure and displayed with ‘ggplot2’. An outline can be provided by the user to specify the spatial domain of interest.\n\n\n\nggh4x: Hacks for ‘ggplot2’\ntags: #ggplot #tidyverse\n[cran package link] https://CRAN.R-project.org/package=ggh4x\n\ndescription from the author/vignette\n\n\nA ‘ggplot2’ extension that does a variety of little helpful things. The package extends ‘ggplot2’ facets through customisation, by setting individual scales per panel, resizing panels and providing nested facets. Also allows multiple colour and fill scales per plot. Also hosts a smaller collection of stats, geoms and axis guides.\n\n\n\ngdiff: Graphical Difference Testing\ntags: #plot #ggplot #data analysis #comparison\n[cran package link] https://CRAN.R-project.org/package=gdiff\ndescription from the author/vignette\n\n\nFunctions for performing graphical difference testing. Differences are generated between raster images. Comparisons can be performed between different package versions and between different R versions.\n\n\n\naplot: Decorate a ‘ggplot’ with Associated Information\ntags: #plot #data analysis #ggplot\n[cran package link] https://CRAN.R-project.org/package=aplot\ndescription from the author/vignette \nFor many times, we are not just aligning plots as what ‘cowplot’ and ‘patchwork’ did. Users would like to align associated information that requires axes to be exactly matched in subplots, e.g. hierarchical clustering with a heatmap. This package provides utilities to aligns associated subplots to a main plot at different sides (left, right, top and bottom) with axes exactly matched.\n\n\ngghighlight: Highlight Lines and Points in ‘ggplot2’\ntags: #plot #data analysis #ggplot\n[cran package link] https://CRAN.R-project.org/package=gghighlight\ndescription from the author/vignette\n\nMake it easier to explore data with highlights.\n\n\n\npdp: Partial Dependence Plots\ntags: #plot #data analysis #ggplot [cran package link] https://CRAN.R-project.org/package=pdp\ndescription from the author/vignette\n\nA general framework for constructing partial dependence (i.e., marginal effect) plots from various types machine learning models in R.\n\n\n\nvcd: Visualizing Categorical Data\ntags: #plot #data analysis #ggplot\n[cran package link] https://CRAN.R-project.org/package=testDriveR\ndescription from the author/vignette\n\nVisualization techniques, data sets, summary and inference procedures aimed particularly at categorical data. Special emphasis is given to highly extensible grid graphics. The package was package was originally inspired by the book “Visualizing Categorical Data” by Michael Friendly and is now the main support package for a new book, “Discrete Data Analysis with R” by Michael Friendly and David Meyer (2015).\n\n\n\ngTestsMulti: New Graph-Based Multi-Sample Tests\ntags: #plot #data analysis #ggplot\n[cran package link] https://CRAN.R-project.org/package=gTestsMulti\ndescription from the author/vignette\n\nNew multi-sample tests for testing whether multiple samples are from the same distribution. They work well particularly for high-dimensional data. Song, H. and Chen, H. (2022) <arXiv:2205.13787>.\n\n\n\nspiralize: Visualize Data on Spirals\ntags: #statistic #visualization #plot\n[cran package link] https://CRAN.R-project.org/package=spiralize\ndescription from the author/vignette\n\nIt visualizes data along an Archimedean spiral https://en.wikipedia.org/wiki/Archimedean_spiral, makes so-called spiral graph or spiral chart. It has two major advantages for visualization: 1. It is able to visualize data with very long axis with high resolution. 2. It is efficient for time series data to reveal periodic patterns.\n\n\n\nvaluemap: Making Choropleth Map\ntags: #plot #valuemap\n[cran package link] https://CRAN.R-project.org/package=valuemap\ndescription from the author/vignette\n\nYou can easily visualize your ‘sf’ polygons or data.frame with h3 address. While ‘leaflet’ package is too raw for data analysis, this package can save data analysts’ efforts & time with pre-set visualize options.\n\n\n\ntessellation: Delaunay and Voronoï Tessellations\ntags: #tesselation #voronoi #delaunay\n[cran package link] https://cran.r-project.org/package=tessellation\ndescription from the author/vignette\n\nDelaunay and Voronoï tessellations, with emphasis on the two-dimensional and the three-dimensional cases (the package provides functions to plot the tessellations for these cases). Delaunay tessellations are computed in C with the help of the ‘Qhull’ library http://www.qhull.org/.\n\n\n\nggdist: Visualizations of Distributions and Uncertainty\ntags: #ggplot #Distributions #Uncertainty\n[cran package link] https://cran.r-project.org/package=ggdist\ndescription from the author/vignette\n\nProvides primitives for visualizing distributions using ‘ggplot2’ that are particularly tuned for visualizing uncertainty in either a frequentist or Bayesian mode. Both analytical distributions (such as frequentist confidence distributions or Bayesian priors) and distributions represented as samples (such as bootstrap distributions or Bayesian posterior samples) are easily visualized. Visualization primitives include but are not limited to: points with multiple uncertainty intervals, eye plots (Spiegelhalter D., 1999) https://ideas.repec.org/a/bla/jorssa/v162y1999i1p45-58.html, density plots, gradient plots, dot plots (Wilkinson L., 1999) doi:10.1080/00031305.1999.10474474, quantile dot plots (Kay M., Kola T., Hullman J., Munson S., 2016) doi:10.1145/2858036.2858558, complementary cumulative distribution function barplots (Fernandes M., Walls L., Munson S., Hullman J., Kay M., 2018) doi:10.1145/3173574.3173718, and fit curves with multiple uncertainty ribbons.\n\n\n\ngrafify: Easy Graphs for Data Visualisation and Linear Models for ANOVA\ntags: #multivariate #Inference #tests #statistics\n[cran package link] https://cran.r-project.org//package=energy\ndescription from the author/vignette\n\nE-statistics (energy) tests and statistics for multivariate and univariate inference, including distance correlation, one-sample, two-sample, and multi-sample tests for comparing multivariate distributions, are implemented. Measuring and testing multivariate independence based on distance correlation, partial distance correlation, multivariate goodness-of-fit tests, k-groups and hierarchical clustering based on energy distance, testing for multivariate normality, distance components (disco) for non-parametric analysis of structured data, and other energy statistics/methods are implemented.\n\n\n\nDiagrammeR: Graph/Network Visualization\ntags: #graph #networks\n[cran package link] https://cran.r-project.org/package=DiagrammeR\ndescription from the author/vignette\n\nBuild graph/network structures using functions for stepwise addition and deletion of nodes and edges. Work with data available in tables for bulk addition of nodes, edges, and associated metadata. Use graph selections and traversals to apply changes to specific nodes or edges. A wide selection of graph algorithms allow for the analysis of graphs. Visualize the graphs and take advantage of any aesthetic properties assigned to nodes and edges.\n\n\n\nnetplot: Beautiful Graph Drawing\ntags: #plot #graph\n[cran package link] https://cran.r-project.org/package=netplot\ndescription from the author/vignette\n\nA graph visualization engine that puts an emphasis on aesthetics at the same time of providing default parameters that yield out-of-the-box-nice visualizations. The package is built on top of ‘The Grid Graphics Package’ and seamlessly work with ‘igraph’ and ‘network’ objects.\n\n\n\nvivid: variable importance and variable interaction displays\ntags: #statistics #clinical data\n[cran package link] https://cran.r-project.org/package=vivid\ndescription from the author/vignette\n\nVariable importance, interaction measures and partial dependence plots are important summaries in the interpretation of statistical and machine learning models. In our R package vivid (variable importance and variable interaction displays) we create new visualisation techniques for exploring these model summaries. We construct heatmap and graph-based displays showing variable importance and interaction jointly, which are carefully designed to highlight important aspects of the fit. We also construct a new matrix-type layout showing all single and bivariate partial dependence plots, and an alternative layout based on graph Eulerians focusing on key subsets. Our new visualisations are model-agnostic and are applicable to regression and classification supervised learning settings. They enhance interpretation even in situations where the number of variables is large and the interaction structure complex.\n\n\n\ngridpattern: ‘grid’ Pattern Grobs\ntags: #database #relational #data\n[cran package link] https://cran.r-project.org/package=gridpattern\ndescription from the author/vignette\n\nProvides ‘grid’ grobs that fill in a user-defined area with various patterns. Includes enhanced versions of the geometric and image-based patterns originally contained in the ‘ggpattern’ package as well as original ‘pch’, ‘polygon_tiling’, ‘regular_polygon’, ‘rose’, ‘text’, ‘wave’, and ‘weave’ patterns plus support for custom user-defined patterns.\n\n\n\nPairViz: Visualization using Graph Traversal\ntags: #graphs #visualization [cran package link] https://cran.r-project.org/package=PairViz\ndescription from the author/vignette\n\nImproving graphics by ameliorating order effects, using Eulerian tours and Hamiltonian decompositions of graphs. References for the methods presented here are C.B. Hurley and R.W. Oldford (2010) doi:10.1198/jcgs.2010.09136 and C.B. Hurley and R.W. Oldford (2011) doi:10.1007/s00180-011-0229-5.\n\n\n\nDiagrammeR: Graph/Network Visualization\ntags: #graph #networks\n[cran package link] https://cran.r-project.org/package=DiagrammeR\ndescription from the author/vignette\n\nBuild graph/network structures using functions for stepwise addition and deletion of nodes and edges. Work with data available in tables for bulk addition of nodes, edges, and associated metadata. Use graph selections and traversals to apply changes to specific nodes or edges. A wide selection of graph algorithms allow for the analysis of graphs. Visualize the graphs and take advantage of any aesthetic properties assigned to nodes and edges.\n\n\n\nggimage: Use Image in ‘ggplot2’\ntags: #ggplot [cran package link] https://cran.r-project.org/package=ggimage\ndescription from the author/vignette\n\nSupports image files and graphic objects to be visualized in ‘ggplot2’ graphic system.\n\n\n\nsuperb: Summary Plots with Adjusted Error Bars\ntags: #ggplot #summary #plots\n[cran package link] https://cran.r-project.org//package=superb\ndescription from the author/vignette\n\nComputes standard error and confidence interval of various descriptive statistics under various designs and sampling schemes. The main function, superbPlot(), can either return a plot or a dataframe with the statistic and its precision interval so that other plotting package can be used. See Cousineau and colleagues (2021) doi:10.1177/25152459211035109 or Cousineau (2017) doi:10.5709/acp-0214-z for a review as well as Cousineau (2005) doi:10.20982/tqmp.01.1.p042, Morey (2008) doi:10.20982/tqmp.04.2.p061, Baguley (2012) doi:10.3758/s13428-011-0123-7, Cousineau & Laurencelle (2016) doi:10.1037/met0000055, Cousineau & O’Brien (2014) doi:10.3758/s13428-013-0441-z, Calderini & Harding doi:10.20982/tqmp.15.1.p001 for specific references.\n\n\n\nkhroma: Colour Schemes for Scientific Data Visualization\ntags: #plot #colors\n[cran package link] https://cran.r-project.org/web/package=khroma\n\nColour schemes ready for each type of data (qualitative, diverging or sequential), with colours that are distinct for all people, including colour-blind readers. This package provides an implementation of Paul Tol (2018) and Fabio Crameri (2018) doi:10.5194/gmd-11-2541-2018 colour schemes for use with ‘graphics’ or ‘ggplot2’. It provides tools to simulate colour-blindness and to test how well the colours of any palette are identifiable. Several scientific thematic schemes (geologic timescale, land cover, FAO soils, etc.) are also implemented\n\n\n\nggside: Side Grammar Graphics\ntags: #plot #ggplot\n[cran package link] https://cran.r-project.org//package=ggside\ndescription from the author/vignette\n\nThe grammar of graphics as shown in ‘ggplot2’ has provided an expressive API for users to build plots. ‘ggside’ extends ‘ggplot2’ by allowing users to add graphical information about one of the main panel’s axis using a familiar ‘ggplot2’ style API with tidy data. This package is particularly useful for visualizing metadata on a discrete axis, or summary graphics on a continuous axis such as a boxplot or a density distribution.\n\n\n\nggquiver: Quiver Plots for ‘ggplot2’\ntags: #plot #ggplot\n[cran package link] https://cran.r-project.org/package=ggquiver\ndescription from the author/vignette\n\nAn extension of ‘ggplot2’ to provide quiver plots to visualise vector fields. This functionality is implemented using a geom to produce a new graphical layer, which allows aesthetic options. This layer can be overlaid on a map to improve visualisation of mapped data.\n\n\n\ntimevis: Create Interactive Timeline Visualizations in R\ntags: #visualization #interactive\n[cran package link] https://cran.r-project.org/package=timevis\ndescription from the author/vignette\n\nCreate rich and fully interactive timeline visualizations. Timelines can be included in Shiny apps and R markdown documents, or viewed from the R console and ‘RStudio’ Viewer. ‘timevis’ includes an extensive API to manipulate a timeline after creation, and supports getting data out of the visualization into R. Based on the ‘vis.js’ Timeline module and the ‘htmlwidgets’ R package.\n\n\n\nmisc3d: Miscellaneous 3D Plots\ntags: #plot #misc\n[cran package link] https://cran.r-project.org//package=misc3d\ndescription from the author/vignette\n\nA collection of miscellaneous 3d plots, including isosurfaces.."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#math",
    "href": "posts/Packages Review 2022/index.html#math",
    "title": "R Packages 2022 list",
    "section": "Math",
    "text": "Math\n\nlmtest: Testing Linear Regression Models\ntags: #linear regression #testing\n[cran package link] https://cran.r-project.org/package=lmtest\ndescription from the author/vignette\n\nA collection of tests, data sets, and examples for diagnostic checking in linear regression models. Furthermore, some generic tools for inference in parametric models are provided.\n\n\n\noptimx: Expanded Replacement and Extension of the ‘optim’ Function\ntags: #optim\n[cran package link] https://cran.r-project.org/packages=optimx\ndescription from the author/vignette\n\nProvides a replacement and extension of the optim() function to call to several function minimization codes in R in a single statement. These methods handle smooth, possibly box constrained functions of several or many parameters. Note that function ‘optimr()’ was prepared to simplify the incorporation of minimization codes going forward. Also implements some utility codes and some extra solvers, including safeguarded Newton methods. Many methods previously separate are now included here."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#statistics",
    "href": "posts/Packages Review 2022/index.html#statistics",
    "title": "R Packages 2022 list",
    "section": "Statistics",
    "text": "Statistics\n\ncorrr: Correlations in R\ntags: #statistics #data #correlation #calculus\n[cran package link] https://CRAN.R-project.org/package=corrr]\ndescription from the author/vignette\n\nA ‘ggplot2’ extension that does a variety of little helpful things. The package extends ‘ggplot2’ facets through customisation, by setting individual scales per panel, resizing panels and providing nested facets. Also allows multiple colour and fill scales per plot. Also hosts a smaller collection of stats, geoms and axis guides.\n\n\n\nFactoMineR: Multivariate Exploratory Data Analysis and Data Mining\ntags: #statistics #pca #clustering #multivariate #data\n[cran package link]https://CRAN.R-project.org/package=FactoMineR\ndescription from the author/vignette\n\nExploratory data analysis methods to summarize, visualize and describe datasets. The main principal component methods are available, those with the largest potential in terms of applications: principal component analysis (PCA) when variables are quantitative, correspondence analysis (CA) and multiple correspondence analysis (MCA) when variables are categorical, Multiple Factor Analysis when variables are structured in groups, etc. and hierarchical cluster analysis. F. Husson, S. Le and J. Pages (2017).\n\n\n\nVIM: Visualization and Imputation of Missing Values\ntags: #data #missing values\n[cran package link] https://CRAN.R-project.org/package=VIM\ndescription from the author/vignette\n\nNew tools for the visualization of missing and/or imputed values are introduced, which can be used for exploring the data and the structure of the missing and/or imputed values. Depending on this structure of the missing values, the corresponding methods may help to identify the mechanism generating the missing values and allows to explore the data including missing values. In addition, the quality of imputation can be visually explored using various univariate, bivariate, multiple and multivariate plot methods. A graphical user interface available in the separate package VIMGUI allows an easy handling of the implemented plot methods.\n\n\n\ncfda: Categorical Functional Data Analysis\ntags: #data #categorical\n[cran package link] https://CRAN.R-project.org/package=cfda\ndescription from the author/vignette\n\nPackage for the analysis of categorical functional data. The main purpose is to compute an encoding (real functional variable) for each state doi:10.3390/math9233074. It also provides functions to perform basic statistical analysis on categorical functional data.\n\n\n\nSHT: Statistical Hypothesis Testing Toolbox\ntags: #statistics #data analysis #comparison\n[cran package link] https://CRAN.R-project.org/package=SHT\ndescription from the author/vignette\n\nWe provide a collection of statistical hypothesis testing procedures ranging from classical to modern methods for non-trivial settings such as high-dimensional scenario. For the general treatment of statistical hypothesis testing, see the book by Lehmann and Romano (2005) doi:10.1007/0-387-27605-X.\n\n\n\ncontingencytables: Statistical Analysis of Contingency Tables\ntags: #plot #data analysis #ggplot\n[cran package link] <https://contingencytables.com/\ndescription from the author/vignette\n\nProvides functions to perform statistical inference of data organized in contingency tables. This package is a companion to the “Statistical Analysis of Contingency Tables” book by Fagerland et al. <ISBN 9781466588172>.\n\n\n\nMorphoTools2: Multivariate Morphometric Analysis\ntags: #statistics #multivatiate [cran package link] https://CRAN.R-project.org/package=MorphoTools2\ndescription from the author/vignette\n\nTools for multivariate analyses of morphological data, wrapped in one package, to make the workflow convenient and fast. Statistical and graphical tools provide a comprehensive framework for checking and manipulating input data, statistical analyses, and visualization of results. Several methods are provided for the analysis of raw data, to make the dataset ready for downstream analyses. Integrated statistical methods include hierarchical classification, principal component analysis, principal coordinates analysis, non-metric multidimensional scaling, and multiple discriminant analyses: canonical, stepwise, and classificatory (linear, quadratic, and the non-parametric k nearest neighbours). The philosophy of the package will be described in Šlenker et al. (in prep).\n\n\n\nautostats: Auto Stats\ntags: #statistic #reports #exploration\n[cran package link]https://CRAN.R-project.org/package=autostats\ndescription from the author/vignette\n\nAutomatically do statistical exploration. Create formulas using ‘tidyselect’ syntax, and then determine cross-validated model accuracy and variable contributions using ‘glm’ and ‘xgboost’. Contains additional helper functions to create and modify formulas. Has a flagship function to quickly determine relationships between categorical and continuous variables in the data set.\n\n\n\nflexclust: Flexible Cluster Algorithms\ntags: #classificatrion #clusters #multivariate\n[cran package link] https://cran.r-project.org/package=flexclust\ndescription from the author/vignette\n\nThe main function kcca implements a general framework for k-centroids cluster analysis supporting arbitrary distance measures and centroid computation. Further cluster methods include hard competitive learning, neural gas, and QT clustering. There are numerous visualization methods for cluster results (neighborhood graphs, convex cluster hulls, barcharts of centroids, …), and bootstrap methods for the analysis of cluster stability.\n\n\n\nffmanova: Fifty-Fifty MANOVA\ntags: #MANOVA #MANCONVA\n[cran package link] https://cran.r-project.org/package=ffmanova\ndescription from the author/vignette\n\nGeneral linear modeling with multiple responses (MANCOVA). An overall p-value for each model term is calculated by the 50-50 MANOVA method by Langsrud (2002) doi:10.1111/1467-9884.00320, which handles collinear responses. Rotation testing, described by Langsrud (2005) doi:10.1007/s11222-005-4789-5, is used to compute adjusted single response p-values according to familywise error rates and false discovery rates (FDR). The approach to FDR is described in the appendix of Moen et al. (2005) doi:10.1128/AEM.71.4.2086-2094.2005. Unbalanced designs are handled by Type II sums of squares as argued in Langsrud (2003) doi:10.1023/A:1023260610025. Furthermore, the Type II philosophy is extended to continuous design variables as described in Langsrud et al. (2007) doi:10.1080/02664760701594246. This means that the method is invariant to scale changes and that common pitfalls are avoided.\n\n\n\ncompareGroups 4.0: Descriptives by groups\ntags: #statistics #clinical data\n[cran package link] https://cran.r-project.org/package=compareGroups\ndescription from the author/vignette\n\ncompareGroups is an R package available on CRAN which performs descriptive tables displaying means, standard deviation, quantiles or frequencies of several variables. Also, p-value to test equality between groups is computed using the appropiate test. With a very simple code, nice, compact and ready-to-publish descriptives table are displayed on R console. They can also be exported to different formats, such as Word, Excel, PDF or inserted in a R-Sweave or R-markdown d\n\n\n\nDescTools: Tools for Descriptive Statistics\ntags: #statistics\n[cran package link] https://cran.r-project.org//package=DescTools\ndescription from the author/vignette\n\nA collection of miscellaneous basic statistic functions and convenience wrappers for efficiently describing data. The author’s intention was to create a toolbox, which facilitates the (notoriously time consuming) first descriptive tasks in data analysis, consisting of calculating descriptive statistics, drawing graphical summaries and reporting the results. The package contains furthermore functions to produce documents using MS Word (or PowerPoint) and functions to import data from Excel. Many of the included functions can be found scattered in other packages and other sources written partly by Titans of R. The reason for collecting them here, was primarily to have them consolidated in ONE instead of dozens of packages (which themselves might depend on other packages which are not needed at all), and to provide a common and consistent interface as far as function and arguments naming, NA handling, recycling rules etc. are concerned. Google style guides were used as naming rules (in absence of convincing alternatives). The ‘BigCamelCase’ style was consequently applied to functions borrowed from contributed R packages as well.\n\n\n\noutForest: Multivariate Outlier Detection and Replacement\ntags: #random forest #outliers\n[cran package link] https://cran.r-project.org/package=outForest\ndescription from the author/vignette\n\nProvides a random forest based implementation of the method described in Chapter 7.1.2 (Regression model based anomaly detection) of Chandola et al. (2009) doi:10.1145/1541880.1541882. It works as follows: Each numeric variable is regressed onto all other variables by a random forest. If the scaled absolute difference between observed value and out-of-bag prediction of the corresponding random forest is suspiciously large, then a value is considered an outlier. The package offers different options to replace such outliers, e.g. by realistic values found via predictive mean matching. Once the method is trained on a reference data, it can be applied to new data.\n\n\n\nmultid: Multivariate Difference Between Two Groups\ntags: #multivariate #test\n[cran package link] https://cran.r-project.org/package=multid\ndescription from the author/vignette\n\nEstimation of multivariate differences between two groups (e.g., multivariate sex differences) with regularized regression methods and predictive approach. See Lönnqvist & Ilmarinen (2021) doi:10.1007/s11109-021-09681-2 and Ilmarinen et al. (2021) doi:10.31234/osf.io/j59bs.\n\n\n\nsimpr: Flexible ‘Tidyverse’-Friendly Simulations\ntags: #simulation #tidyverse\n[cran package link] https://cran.r-project.org/package=simpr\ndescription from the author/vignette\n\nA general, ‘tidyverse’-friendly framework for simulation studies, design analysis, and power analysis. Specify data generation, define varying parameters, generate data, fit models, and tidy model results in a single pipeline, without needing loops or custom functions.\n\n\n\nggfortify: Data Visualization Tools for Statistical Analysis Results\ntags: #statistics #datavis\n[cran package link] https://cran.r-project.org/web/packages/ggfortify/index.html\ndescription from the author/vignette\n\nUnified plotting tools for statistics commonly used, such as GLM, time series, PCA families, clustering and survival analysis. The package offers a single plotting interface for these analysis results and plots in a unified style using ‘ggplot2’.\n\n\n\nMVTests: Multivariate Hypothesis Tests\ntags: #statistics #test #multivariate\n[cran package link] https://cran.r-project.org/package=MVTests\ndescription from the author/vignette\n\nMultivariate hypothesis tests and the confidence intervals. It can be used to test the hypothesizes about mean vector or vectors (one-sample, two independent samples, paired samples), covariance matrix (one or more matrices), and the correlation matrix. Moreover, it can be used for robust Hotelling T^2 test at one sample case in high dimensional data. For this package, we have benefited from the studies Rencher (2003), Nel and Merwe (1986) doi:10.1080/03610928608829342, Tatlidil (1996), Tsagris (2014), Villasenor Alva and Estrada (2009) doi:10.1080/03610920802474465.\n\n\n\nplsVarSel: Variable Selection in Partial Least Squares\ntags: #pls #chemometrics\n[cran package link] https://cran.r-project.org/packages=plsVarSel\ndescription from the author/vignette\n\nInterfaces and methods for variable selection in Partial Least Squares. The methods include filter methods, wrapper methods and embedded methods. Both regression and classification is supported.\n\n\n\nRcmdrPlugin.EZR: R Commander Plug-in for the EZR (Easy R) Package\ntags: #statistics #ROC\n[cran package link] https://cran.r-project.org/package=RcmdrPlugin.EZR/index.html\ndescription from the author/vignette\n\nEZR (Easy R) adds a variety of statistical functions, including survival analyses, ROC analyses, metaanalyses, sample size calculation, and so on, to the R commander. EZR enables point-and-click easy access to statistical functions, especially for medical statistics. EZR is platform-independent and runs on Windows, Mac OS X, and UNIX. Its complete manual is available only in Japanese (Chugai Igakusha, ISBN: 978-4-498-10918-6, Nankodo, ISBN: 978-4-524-26158-1, Ohmsha, ISBN: 978-4-274-22632-8), but an report that introduced the investigation of EZR was published in Bone Marrow Transplantation (Nature Publishing Group) as an Open article. This report can be used as a simple manual. It can be freely downloaded from the journal website as shown below. This report has been cited in more than 3,000 scientific articles.\n\n\n\nRcmdrPlugin.NMBU: R Commander Plug-in for University Level Applied Statistics\ntags: #PLS #LDA #QDA\n[cran package link] https://cran.r-project.org/package=RcmdrPlugin.NMBU\ndescription from the author/vignette\n\nAn R Commander “plug-in” extending functionality of linear models and providing an interface to Partial Least Squares Regression and Linear and Quadratic Discriminant analysis. Several statistical summaries are extended, predictions are offered for additional types of analyses, and extra plots, tests and mixed models are available.\n\n\n\nDataEditR: An Interactive Editor for Viewing, Entering, Filtering & Editing Data\ntags: #tables #editor\n[cran package link] https://cran.r-project.org/package=DataEditR\ndescription from the author/vignette\n\nAn interactive editor built on ‘rhandsontable’ to allow the interactive viewing, entering, filtering and editing of data in R https://dillonhammill.github.io/DataEditR/.\n\n\n\nfICA: Classical, Reloaded and Adaptive FastICA Algorithms\ntags: #ggplot #summary #plots\n[cran package link] https://cran.r-project.org/package=fICA\ndescription from the author/vignette\n\nAlgorithms for classical symmetric and deflation-based FastICA, reloaded deflation-based FastICA algorithm and an algorithm for adaptive deflation-based FastICA using multiple nonlinearities. For details, see Miettinen et al. (2014) doi:10.1109/TSP.2014.2356442 and Miettinen et al. (2017) doi:10.1016/j.sigpro.2016.08.028. The package is described in Miettinen, Nordhausen and Taskinen (2018) doi:10.32614/RJ-2018-046.\n\n\n\nJFE: Tools and GUI for Analyzing Time Series Data of Just Finance and Econometrics\ntags: #econometrics #finance\n[cran package link] https://cran.r-project.org/web/packages/JFE/index.html\ndescription from the author/vignette\n\nSupport the analysis of financial and econometric time series, including recursive forecasts for machine learning.\n\n\n\nanscombiser: Create Datasets with Identical Summary Statistics\ntags: #statistics #anscombe\n[cran package link] https://cran.r-project.org/package=anscombiser\ndescription from the author/vignette\n\nThe anscombiser package takes a simpler and quicker approach to the same problem, using Anscombe’s statistics. It uses shifting, scaling and rotating to transform the observations in an input dataset to achieve a target set of Anscombe’s statistics”\n\n\n\nrandtoolbox: Toolbox for Pseudo and Quasi Random Number Generation and Random Generator Tests\ntags: #distributions\n[cran package link] https://cran.r-project.org/package=randtoolbox\ndescription from the author/vignette\n\nProvides (1) pseudo random generators - general linear congruential generators, multiple recursive generators and generalized feedback shift register (SF-Mersenne Twister algorithm and WELL generators); (2) quasi random generators - the Torus algorithm, the Sobol sequence, the Halton sequence (including the Van der Corput sequence) and (3) some generator tests - the gap test, the serial test, the poker test. See e.g. Gentle (2003) doi:10.1007/b97336. The package can be provided without the rngWELL dependency on demand. Take a look at the Distribution task view of types and tests of random number generators. Version in Memoriam of Diethelm and Barbara Wu"
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#medicine",
    "href": "posts/Packages Review 2022/index.html#medicine",
    "title": "R Packages 2022 list",
    "section": "Medicine",
    "text": "Medicine\n\nvisR: Clinical Graphs and Tables Adhering to Graphical Principles\ntags: #data #clinical\n[cran package link] https://CRAN.R-project.org/package=cfda\ndescription from the author/vignette\n\nTo enable fit-for-purpose, reusable clinical and medical research focused visualizations and tables with sensible defaults and based on graphical principles as described in: “Vandemeulebroecke et al. (2018)” doi:10.1002/pst.1912, “Vandemeulebroecke et al. (2019)” doi:10.1002/psp4.12455, and “Morris et al. (2019)” doi:10.1136/bmjopen-2019-030215.\n\n\n\nvbp: Blood Pressure Analysis in R\ntags: #statistics #clinical data\n[cran package link] https://cran.r-project.org/package=bp\ndescription from the author/vignette\n\nCardiovascular disease (CVD) is the leading cause of death worldwide with Hypertension, specifically, affecting over 1.1 billion people annually. The goal of the package is to provide a comprehensive toolbox for analyzing blood pressure data using a variety of statistical metrics and visualizations to bring more clarity to CVD."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#teaching",
    "href": "posts/Packages Review 2022/index.html#teaching",
    "title": "R Packages 2022 list",
    "section": "Teaching",
    "text": "Teaching\n\ntestDriveR: Teaching Data for Statistics and Data Science\ntags: #plot #data analysis #ggplot\n[cran package link] https://CRAN.R-project.org/package=testDriveR\ndescription from the author/vignette\n\nProvides data sets for teaching statistics and data science courses. It includes a sample of data from John Edmund Kerrich’s famous coinflip experiment. These are data that I used for teaching SOC 4015 / SOC 5050 at Saint Louis University (SLU). The package also contains an R Markdown template with the required formatting for assignments in my courses SOC 4015, SOC 4650, SOC 5050, and SOC 5650 at SLU."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#chemistry",
    "href": "posts/Packages Review 2022/index.html#chemistry",
    "title": "R Packages 2022 list",
    "section": "Chemistry",
    "text": "Chemistry\n\nstoichcalc: R Functions for Solving Stoichiometric Equations\ntags: #chemistry #stoichiometry [cran package link] https://CRAN.R-project.org/package=stoichcalc\ndescription from the author/vignette\n\nGiven a list of substance compositions, a list of substances involved in a process, and a list of constraints in addition to mass conservation of elementary constituents, the package contains functions to build the substance composition matrix, to analyze the uniqueness of process stoichiometry, and to calculate stoichiometric coefficients if process stoichiometry is unique. (See Reichert, P. and Schuwirth, N., A generic framework for deriving process stoichiometry in enviromental models, Environmental Modelling and Software 25, 1241-1251, 2010 for more details.)\n\n\n\ninters: Flexible Tools for Estimating Interactions\ntags: #statistics #interactions [cran package link] https://CRAN.R-project.org/package=inters\ndescription from the author/vignette\n\nA set of functions to estimate interactions flexibly in the face of possibly many controls. Implements the procedures described in Blackwell and Olson (2022) doi:10.1093/restud/rdt044.\n\n\n\nwaves: Vis-NIR Spectral Analysis Wrapper\ntags: #spectroscopy #preprocessing #filtering #model training\n[cran package link] https://cran.r-project.org/package=waves\ndescription from the author/vignette\n\nOriginally designed application in the context of resource-limited plant research and breeding programs, ‘waves’ provides an open-source solution to spectral data processing and model development by bringing useful packages together into a streamlined pipeline. This package is wrapper for functions related to the analysis of point visible and near-infrared reflectance measurements. It includes visualization, filtering, aggregation, preprocessing, cross-validation set formation, model training, and prediction functions to enable open-source association of spectral and reference data. This package is documented in a peer-reviewed manuscript in the Plant Phenome Journal doi:10.1002/ppj2.20012. Specialized cross-validation schemes are described in detail in Jarquín et al. (2017) doi:10.3835/plantgenome2016.12.0130. Example data is from Ikeogu et al. (2017) doi:10.1371/journal.pone.0188918.\n\n\n\nMSclassifR: Automated Classification of Mass Spectra\ntags: #Classification #Mass-Spectra\n[cran package link] https://cran.r-project.org//package=MSclassifR\ndescription from the author/vignette\n\nFunctions to classify mass spectra in known categories, and to determine discriminant mass-over-charge values. It includes easy-to-use functions for pre-processing mass spectra, functions to determine discriminant mass-over-charge values (m/z) from a library of mass spectra corresponding to different categories, and functions to predict the category (species, phenotypes, etc.) associated to a mass spectrum from a list of selected mass-over-charge values. Two vignettes illustrating how to use the functions of this package from real data sets are also available online to help users: https://agodmer.github.io/MSclassifR_examples/Vignettes/Vignettemsclassifr_Ecrobia.html and https://agodmer.github.io/MSclassifR_examples/Vignettes/Vignettemsclassifr_Klebsiella.html.\n\n\n\nNGLVieweR: load a PDB in R in order to view it\ntags: #chemistrys #visualization #molecular\n[cran package link] https://cran.r-project.org/packages=NGLVieweR\ndescription from the author/vignette\n\nProvides an ‘htmlwidgets’ https://www.htmlwidgets.org/ interface to ‘NGL.js’ http://nglviewer.org/ngl/api/. ‘NGLvieweR’ can be used to visualize and interact with protein databank (‘PDB’) and structural files in R and Shiny applications. It includes a set of API functions to manipulate the viewer after creation in Shiny."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#writing-reports-and-articles",
    "href": "posts/Packages Review 2022/index.html#writing-reports-and-articles",
    "title": "R Packages 2022 list",
    "section": "Writing reports and articles",
    "text": "Writing reports and articles\n\nutile.tools: Summarize Data for Publication\ntags: #statistic #reports #exploration\n[cran package link] [https://CRAN.R-project.org/package=utile.tools]\ndescription from the author/vignette\n\nA set of tools for preparing and summarizing data for publication purposes. Includes functions for tabulating models, means to produce human-readable summary statistics from raw data, macros for calculating duration of time, and simplistic hypothesis testing tools.\n\n\n\nrrtable: Reproducible Research with a Table of R Codes\ntags: #tables #reproducible research\n[cran package link] https://cran.r-project.org/package=rrtable\ndescription from the author/vignette\n\nMakes documents containing plots and tables from a table of R codes. Can make “HTML”, “pdf(‘LaTex’)”, “docx(‘MS Word’)” and “pptx(‘MS Powerpoint’)” documents with or without R code. In the package, modularized ‘shiny’ app codes are provided. These modules are intended for reuse across applications.\n\n\n\nreporter: Creates Statistical Reports\ntags: #statistics #report\n[cran package link] https://CRAN.R-project.org/package=reporter\ndescription from the author/vignette\n\nContains functions to create regulatory-style statistical reports. Originally designed to create tables, listings, and figures for the pharmaceutical, biotechnology, and medical device industries, these reports are generalized enough that they could be used in any industry. Generates text, rich-text, PDF, HTML, and Microsoft Word file formats. The package specializes in printing wide and long tables with automatic page wrapping and splitting. Reports can be produced with a minimum of function calls, and without relying on other table packages. The package supports titles, footnotes, page header, page footers, spanning headers, page by variables, and automatic page numbering.\n\n\n\nPDE: Extract Tables and Sentences from PDFs with User Interface\ntags: #pdf #scraping\n[cran package link] https://cran.r-project.org/packages=PDE\ndescription from the author/vignette\n\nPDE is a R package that easily extracts information and tables from PDF files. The PDE_analyzer_i() performs the sentence and table extraction while the included PDE_reader_i() allows the user-friendly visualization and quick-processing of the obtained results.\n\n\n\nTplyr: A Grammar of Clinical Data Summary\ntags: #clinical #medical\n[cran package link] https://cran.r-project.org/package=Tplyr\ndescription from the author/vignette\n\nA tool created to simplify the data manipulation necessary to create clinical reports."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#coding",
    "href": "posts/Packages Review 2022/index.html#coding",
    "title": "R Packages 2022 list",
    "section": "Coding",
    "text": "Coding\n\nmockr: Mocking in R\ntags: #testing\n[cran package link] https://cran.r-project.org/package=mockr\ndescription from the author/vignette\n\nProvides a means to mock a package function, i.e., temporarily substitute it for testing. Designed as a drop-in replacement for the now deprecated ‘testthat::with_mock()’ and ‘testthat::local_mock()’.\n\n\n\ncOde: Automated C Code Generation for ‘deSolve’, ‘bvpSolve’\ntags: #C #Jacobians\n[cran package link] https://cran.r-project.org/package=cOde\ndescription from the author/vignette\n\nGenerates all necessary C functions allowing the user to work with the compiled-code interface of ode() and bvptwp(). The implementation supports “forcings” and “events”. Also provides functions to symbolically compute Jacobians, sensitivity equations and adjoint sensitivities being the basis for sensitivity analysis.\n\n\n\nmatlab2r: Translation Layer from MATLAB to R\ntags: #R #Matlab\n[cran package link] https://cran.r-project.org/package=matlab2r\ndescription from the author/vignette\n\nAllows users familiar with MATLAB to use MATLAB-named functions in R. Several basic MATLAB functions are written in this package to mimic the behavior of their original counterparts, with more to come as this package grows.\n\n\n\nlessR: Less Code, More Results\ntags: #coding\n[cran package link] https://cran.r-project.org//package=lessR\ndescription from the author/vignette\n\nEach function accomplishes the work of several or more standard R functions. For example, two function calls, Read() and CountAll(), read the data and generate summary statistics for all variables in the data frame, plus histograms and bar charts as appropriate. Other functions provide for descriptive statistics, a comprehensive regression analysis, analysis of variance and t-test, plotting including the introduced here Violin/Box/Scatter plot for a numerical variable, bar chart, histogram, box plot, density curves, calibrated power curve, reading multiple data formats with the same function call, variable labels, color themes, Trellis graphics and a built-in help system. Also includes a confirmatory factor analysis of multiple indicator measurement models, pedagogical routines for data simulation such as for the Central Limit Theorem, and generation and rendering of R markdown instructions for interpretative output.\n\n\n\nGroundhog: Addressing The Threat That R Poses To Reproducible Research\ntags: #reproducibility\n[cran package link] https://cran.r-project.org/package=groundhog\ndescription from the author/vignette\n\nMake R scripts that rely on packages reproducible, by ensuring that every time a given script is run, the same version of the used packages are loaded (instead of whichever version the user running the script happens to have installed). This is achieved by using the new command groundhog.library() instead of the base command library(), and including a date in the call. The date is used to call on the same version of the package every time (the most recent version available on CRAN at that date)."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#graphics",
    "href": "posts/Packages Review 2022/index.html#graphics",
    "title": "R Packages 2022 list",
    "section": "Graphics",
    "text": "Graphics\n\nraymolecule: Parse and Render Molecular Structures in 3D\ntags: #chemistry #rendering\n[cran package link] https://cran.r-project.org/package=raymolecule\ndescription from the author/vignette\n\nDownloads and parses ‘SDF’ (Structural Description Format) and ‘PDB’ (Protein Database) files for 3D rendering."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#regression",
    "href": "posts/Packages Review 2022/index.html#regression",
    "title": "R Packages 2022 list",
    "section": "Regression",
    "text": "Regression\n\nspeedglm: Fitting Linear and Generalized Linear Models to Large Data Sets\ntags: #fitting #GLM\n[cran package link] https://cran.r-project.org//package=speedglm\ndescription from the author/vignette\n\nFitting linear models and generalized linear models to large data sets by updating algorithms.\n\n\n\nmodelsummary: Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready\ntags: #models\n[cran package link] https://cran.r-project.org/package=modelsummary\ndescription from the author/vignette\n\nCreate beautiful and customizable tables to summarize several statistical models side-by-side. Draw coefficient plots, multi-level cross-tabs, dataset summaries, balance tables (a.k.a. “Table 1s”), and correlation matrices. This package supports dozens of statistical models, and it can produce tables in HTML, LaTeX, Word, Markdown, PDF, PowerPoint, Excel, RTF, JPG, or PNG. Tables can easily be embedded in ‘Rmarkdown’ or ‘knitr’ dynamic documents."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#signal-processing",
    "href": "posts/Packages Review 2022/index.html#signal-processing",
    "title": "R Packages 2022 list",
    "section": "Signal Processing",
    "text": "Signal Processing\n\ngsignal: Signal Processing in R\ntags: #signal processing #filters #boxcar\n[cran package link] https://cran.r-project.org/packages=gsignal\ndescription from the author/vignette\n\nR implementation of the ‘Octave’ package ‘signal’, containing a variety of signal processing tools, such as signal generation and measurement, correlation and convolution, filtering, filter design, filter analysis and conversion, power spectrum analysis, system identification, decimation and sample rate change, and windowing."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#data-analysis",
    "href": "posts/Packages Review 2022/index.html#data-analysis",
    "title": "R Packages 2022 list",
    "section": "Data analysis",
    "text": "Data analysis\n\nsplitTools: Tools for Data Splitting\ntags: #data splitting\n[cran package link] https://cran.r-project.org/package=splitTools\ndescription from the author/vignette\n\nFast, lightweight toolkit for data splitting. Data sets can be partitioned into disjoint groups (e.g. into training, validation, and test) or into (repeated) k-folds for subsequent cross-validation. Besides basic splits, the package supports stratified, grouped as well as blocked splitting. Furthermore, cross-validation folds for time series data can be created. See e.g. Hastie et al. (2001) doi:10.1007/978-0-387-84858-7 for the basic background on data partitioning and cross-validation.\n\n\n\noptedr: Calculating Optimal and D-Augmented Designs\ntags: #DoE #Chemometrics #optimal-design\n[cran package link] https://cran.r-project.org//package=optedr\ndescription from the author/vignette\n\nCalculates D-, Ds-, A- and I-optimal designs for non-linear models, via an implementation of the cocktail algorithm (Yu, 2011, doi:10.1007/s11222-010-9183-2). Compares designs via their efficiency, and D-augments any design with a controlled efficiency. An efficient rounding function has been provided to transform approximate designs to exact designs. mynotes\n\n\n\nReDaMoR: Relational Data Modeler\ntags: #database #relational #data\n[cran package link] https://cran.r-project.org/package=ReDaMoR\ndescription from the author/vignette\n\nThe aim of this package is to manipulate relational data models in R. It provides functions to create, modify and export data models in json format. It also allows importing models created with ‘MySQL Workbench’ (https://www.mysql.com/products/workbench/). These functions are accessible through a graphical user interface made with ‘shiny’. Constraints such as types, keys, uniqueness and mandatory fields are automatically checked and corrected when editing a model. Finally, real data can be confronted to a model to check their compatibility.\n\n\n\nexplore: Simplifies Exploratory Data Analysis\ntags: #graphs #visualization\n[cran package link] https://cran.r-project.org/package=gridpattern\ndescription from the author/vignette\n\nInteractive data exploration with one line of code or use an easy to remember set of tidy functions for exploratory data analysis. Introduces three main verbs. explore() to graphically explore a variable or table, describe() to describe a variable or table and report() to create an automated report.\n\n\n\nesquisse: Explore and Visualize Your Data Interactivelly\ntags: #visualization #interactive\n[cran package link] https://cran.r-project.org/package=esquisse\ndescription from the author/vignette\n\nA ‘shiny’ gadget to create ‘ggplot2’ figures interactively with drag-and-drop to map your variables to different aesthetics. You can quickly visualize your data accordingly to their type, export in various formats, and retrieve the code to reproduce the plot.\n\n\n\nplfMA: A GUI to View, Design and Export Various Graphs of Data\ntags: #visualization #GUI\n[cran package link] http://cran.stat.unipd.it/package=plfMA\ndescription from the author/vignette\n\nProvides a graphical user interface for viewing and designing various types of graphs of the data. The graphs can be saved in different formats of an image.\n\n\n\ndatasets.load: Interfaces for Loading Datasets\ntags: #visualization #interactive\n[cran package link] https://cran.r-project.org/packages/datasets.load/index.html\ndescription from the author/vignette\n\nVisual interface for loading datasets in RStudio from all installed (including unloaded) packages, also includes command line interfaces.\n\n\n\nloon.shiny: Automatically Create a ‘Shiny’ App Based on Interactive ‘Loon’ Widgets\ntags: #data analysis\n[cran package link] https://cran.r-project.org/package=loon.shiny\ndescription from the author/vignette\n\nPackage ‘shiny’ provides interactive web applications in R. Package ‘loon’ is an interactive toolkit engaged in open-ended, creative and unscripted data exploration. The ‘loon.shiny’ package can take ‘loon’ widgets and display a selfsame ‘shiny’ app.\n\n\n\nloon: Interactive Statistical Data Visualization\ntags: #plot #data analysis\n[cran package link] https://cran.r-project.org//package=loon\ndescription from the author/vignette\n\nAn extendable toolkit for interactive data visualization and exploration.\n\n\n\nrio: A Swiss-Army Knife for Data I/O\ntags: #data input\n[cran package link] https://cran.r-project.org/package=rio\ndescription from the author/vignette\n\nStreamlined data import and export by making assumptions that the user is probably willing to make: ‘import()’ and ‘export()’ determine the data structure from the file extension, reasonable defaults are used for data import and export (e.g., ‘stringsAsFactors=FALSE’), web-based import is natively supported (including from SSL/HTTPS), compressed files can be read directly without explicit decompression, and fast import packages are used where appropriate. An additional convenience function, ‘convert()’, provides a simple method for converting between file types.\n\n\n\ntabxplor: User-Friendly Tables with Color Helpers for Data Exploration\ntags: #plots #tables\n[cran package link] https://cran.r-project.org/package=tabxplor\ndescription from the author/vignette\n\nMake it easy to deal with multiple cross-tables in data exploration, by creating them, manipulating them, and adding color helpers to highlight important informations. All functions are “tidy”, pipe-friendly, and render data frames which can be easily manipulated. Tables can be exported to Excel and in html with formats and colors.\n\n\n\ngroupdata2: Creating Groups from Data\ntags: #tables #data\n[cran package link] https://cran.r-project.org//package=groupdata2\ndescription from the author/vignette\n\nhods for dividing data into groups. Create balanced partitions and cross-validation folds. Perform time series windowing and general grouping and splitting of data. Balance existing groups with up- and downsampling or collapse them to fewer groups.\n\n\n\nconjurer: A Parametric Method for Generating Synthetic Data\ntags: #plot #colors\n[cran package link] https://cran.r-project.org//package=conjurer\ndescription from the author/vignette\n\nBuilds synthetic data applicable across multiple domains. This package also provides flexibility to control data distribution to make it relevant to many industry examples\n\n\n\nowidR: A Package for Importing Data from Our World in Data\ntags: #data #statistics\n[cran package link] https://cran.r-project.org/package=owidR\ndescription from the author/vignette\n\nScrapes data from the Our World in Data website to offer easy to use functions for searching for datasets and downloading them into R.\n\n\n\ntidycharts: Generate Tidy Charts Inspired by ‘IBCS’\ntags: #plots\n[cran package link] https://cran.r-project.org/package=tidycharts\ndescription from the author/vignette\n\nThere is a wide range of R packages created for data visualization, but still, there was no simple and easily accessible way to create clean and transparent charts - up to now. The ‘tidycharts’ package enables the user to generate charts compliant with International Business Communication Standards (‘IBCS’). It means unified bar widths, colors, chart sizes, etc. Creating homogeneous reports has never been that easy! Additionally, users can apply semantic notation to indicate different data scenarios (plan, budget, forecast). What’s more, it is possible to customize the charts by creating a personal color pallet with the possibility of switching to default options after the experiments. We wanted the package to be helpful in writing reports, so we also made joining charts in a one, clear image possible. All charts are generated in SVG format and can be shown in the ‘RStudio’ viewer pane or exported to HTML output of ‘knitr’/‘markdown’."
  },
  {
    "objectID": "posts/Packages Review 2022/index.html#extra",
    "href": "posts/Packages Review 2022/index.html#extra",
    "title": "R Packages 2022 list",
    "section": "EXTRA",
    "text": "EXTRA\n\ntidydice: simulates rolling a dice and flipping a coin\ntags: #teaching #fun\n[cran package link] https://cran.r-project.org//package=tidydice\ndescription from the author/vignette\n\nThis package simulates rolling a dice and flipping a coin. Each experiment generates a tibble. Dice rolls and coin flips are simulated using sample(). The properties of the dice can be changed, like the number of sides. A coin flip is simulated using a two sided dice. Experiments can be combined with the pipe-operator.\n\n\n\ntiling:Polygon Tiling Examples\ntags: #arts #fun\n[cran package link] https://cran.rstudio.com/web/package=gridpattern\ndescription from the author/vignette\n\nSeveral uniform regular polygon tiling patterns can be achieved by use of grid.pattern_regular_polygon() plus occasionally grid.polygon() to set a background color. This vignette highlights several such tiling patterns plus a couple notable non-uniform tiling patterns.\n\n\n\nlingtypology: Linguistic Typology and Mapping\ntags: #linguistic mapping\n[cran package link] https://cran.r-project.org/package=lingtypology\ndescription from the author/vignette\n\nProvides R with the Glottolog database https://glottolog.org/ and some more abilities for purposes of linguistic mapping. The Glottolog database contains the catalogue of languages of the world. This package helps researchers to make a linguistic maps, using philosophy of the Cross-Linguistic Linked Data project https://clld.org/, which allows for while at the same time facilitating uniform access to the data across publications. A tutorial for this package is available on GitHub pages https://docs.ropensci.org/lingtypology/ and package vignette. Maps created by this package can be used both for the investigation and linguistic teaching. In addition, package provides an ability to download data from typological databases such as WALS, AUTOTYP and some others and to create your own database website."
  },
  {
    "objectID": "posts/Tip05/index.html",
    "href": "posts/Tip05/index.html",
    "title": "Tip 4: boxplots and scatterplots: simple recipes",
    "section": "",
    "text": "Summary\n\nSimulate data, check and assign data types\nCreate a scatterplot with ggplot\nCreate violin plot with ggstatsplot\n\nExample 1: We want to visualize the difference between two groups of patients that follow two different diets. Group A has an average of total cholesterol of 180 with a standard deviation of 20 while Group B and average of 200 with a standard deviation of 40\n\nlibrary(MASS)\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(data.table)\n\nWarning: package 'data.table' was built under R version 4.2.3\n\nnpatientsA <- 500\nnpatientsB <- 520\ncholA <- mvrnorm(n=npatientsA, mu=180, Sigma=20, empirical=T)\ncholB <- mvrnorm(n=npatientsB, mu=200, Sigma=40, empirical=T)\n\ndataA <- cbind(cholA,rep(\"A\",npatientsA))  \ndataB <- cbind(cholB,rep(\"B\",npatientsB))  \n\ndata <- data.frame(rbind(dataA,dataB))\ncolnames(data) <- c(\"Cholesterol\",\"group\")\ndata$Cholesterol <- as.numeric(data$Cholesterol)\n\np1 <-ggplot(data, aes(x = group, y = Cholesterol)) + geom_jitter(alpha=0.05) \n\np1\n\n\n\n\nA few observations on the code. First of all, we need to input the data in a data.frame otherwise ggplot will give us an error. The second observation is that since we put chr labels on our groups we needed to define Cholesterol as.numeric in order to avoid unwanted resultsstrange results. Try to comment the line data$Cholesterol <- as.numeric(data$Cholesterol) and you can see by yourself what will happen. (hint: a “labelstorm!”)\nJiiter plots is one of my favorite way to represent data. data and immediately understand the distribution of your data and also avoid the pitfall of boxplot (see (Matejka and Fitzmaurice 2017))\nIf you need inferential statistics on your data another resource is (Patil 2021). See the following example with our data. NOTE that we nee to transform the group label as.factor\n\nlibrary(ggstatsplot)\n\nWarning: package 'ggstatsplot' was built under R version 4.2.3\n\n\nYou can cite this package as:\n     Patil, I. (2021). Visualizations with statistical details: The 'ggstatsplot' approach.\n     Journal of Open Source Software, 6(61), 3167, doi:10.21105/joss.03167\n\ndata$group <- as.factor(data$group)\n\npstack  <- ggbetweenstats(data,group,Cholesterol)\n                          \npstack    \n\n\n\n\n\n\n\n\nReferences\n\nMatejka, Justin, and George Fitzmaurice. 2017. “Same Stats, Different Graphs.” Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems, May. https://doi.org/10.1145/3025453.3025912.\n\n\nPatil, Indrajeet. 2021. “Visualizations with Statistical Details: The ’Ggstatsplot’ Approach” 6: 3167. https://doi.org/10.21105/joss.03167."
  },
  {
    "objectID": "listing.html",
    "href": "listing.html",
    "title": "Blog",
    "section": "",
    "text": "R Packages 2022 list\n\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\nGiorgio Luciano\n\n\n\n\n\n\n\n\nTip 1: ggplot loops\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2023\n\n\nGiorgio Luciano\n\n\n\n\n\n\n\n\nTip 2: Cleaning column names of an imported csv\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2023\n\n\nGiorgio Luciano\n\n\n\n\n\n\n\n\nTip 3: Functions for simulating data\n\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2023\n\n\nGiorgio Luciano\n\n\n\n\n\n\n\n\nTip 4: boxplots and scatterplots: simple recipes\n\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2023\n\n\nGiorgio Luciano\n\n\n\n\n\n\nNo matching items"
  }
]